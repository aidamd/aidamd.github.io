<head>
    <link rel="stylesheet" type="text/css" href="styles_0.css">
    <link href='https://fonts.googleapis.com/css?family=Comfortaa' rel='stylesheet'>
    <title>Aida Mostafazadeh Davani</title>
    <meta name="google-site-verification" content="A3s6dd9Jhb84f00ekhDar1ib71BOjNIbescOYtG-8yg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<div id = "main">
    <div id = "left">
        <div class="left_div" id="content">
            <img id="my_name" src="img/aida_gold.png">
            <h2>Aida Mostafazadeh Davani</h2>
            <img id="me" src="img/aida3.jpg">
        </div>

        <div class="left_div" id="new">
            <h3>News:</h3>
	    <span class="time">Febuary 2024</span>: I'll be a keynote speaker of the Computational Psychology preconference at SPSP 2024.<br><br>
            <span class="time">August 2022</span>: I joined the Responsible AI team at Google Research
            as a research scientist.<br><br>
            <span class="time">April 2022</span>: I successfully defended my defense thesis on
            "Integrating Annotator Biases into Modeling Subjective Language Classification Tasks."<br><br>
            <span class="time">January 2022</span>: I am co-organizing <a href="https://www.workshopononlineabuse.com/">
            Workshop on Online Abuse and Harms</a> at NAACL 2022.<br><br>
            <span class="time">August 2021</span>: I will continue collaborating with Google Ethical AI team,
            as a student researcher, until Dec 2021.<br><br>
            <span class="time">May 2021</span>: I started working as a research intern
            at Google's Ethical AI team.<br><br>
            <span class="time">January 2020</span>: I am co-organizing the <a href="https://www.workshopononlineabuse.com/">
            Workshop on Online Abuse and Harms</a> at ACL 2021.<br><br>
            <span class="time">April 2020</span>: Our paper is accepted for presentation as a talk <br> at
            <a href="https://cognitivesciencesociety.org/cogsci-2020/">CogSci 2020</a>. <br><br>
            <span class="time">April 2020</span>: Our paper, a collaboration with INK lab,
            is accepted as short paper in
            <a href="https://acl2020.org/">ACL 2020</a>!<br><br>
            <span class="time">January 2020</span>: I will be attending
            <a href="http://meeting.spsp.org/">SPSP</a> conference in New Orleans, LA.

        </div>
    </div>
    <div id = "right">
        <div class="right_div">
            <h2 class="right">About</h2>
	I am a research scientist in the Responsible AI team at Google Research. My research is dedicated to advancing the development and evaluation of NLP models by incorporating social, psychological, and cultural factors that shape our perceptions of language. Focusing on established social scientific theories and NLP models, my research aims to make language models more representative of the complexities and distinctions of humans and cultures.
<br><br>
Before joining Google Research, I was a research assistant in the Computational Social Science lab at <a href="https://www.cs.usc.edu/">
           University of Southern California (USC)</a>, where I received my PhD in Computer Science working on the impact of cognitive biases and stereotypes on the design and implementation of supervised NLP models. My research has led to NLP models for incorporating annotators' perspectives into text classifiers, identifying moral expressions in language, detecting unreported hate crime incidents from local news articles, and mitigating bias in hate speech classification.
            <br><br>

            Feel free to <a href="mailto:aidamd@google.com">Email</a> me, check my <a href="Aida_CV.pdf">CV</a>,
            explore my <a href="https://scholar.google.com/citations?hl=en&user=byZIaXsAAAAJ&view_op=list_works&sortby=pubdate"
            >Google Scholar</a>, clone my projects on <a href="https://github.com/aidamd">GitHub</a>, or even connect via
            <a href="https://www.linkedin.com/in/aida-mostafazadeh-davani-345a927b/">LinkedIn</a>!

        </div>
        
        <div class="right_div">
            <h2 class="right">Publications</h2>

            <ul>
	    <li>
                <a class="title" href="https://arxiv.org/pdf/2404.05866">
                    GeniL: A Multilingual Dataset on Generalizing Language </a><br>
                <u>Aida Davani</u>,* Sagar Gubbi,* Sunipa Dev, Shachi Dave, Vinodkumar Prabhakaran<br>
		COLM, 2024.
            </li>
	    <li>
                <a class="title" href="https://arxiv.org/pdf/2312.06861.pdf">
                    Disentangling perceptions of offensiveness: Cultural and moral correlates</a><br>
                <u>Aida Davani</u>, Mark Díaz, Dylan Baker, Vinodkumar Prabhakaran<br>
		FAccT, 2024.
            </li>
	    <li>
                <a class="title" href="https://arxiv.org/pdf/2311.05074">
                    GRASP: A Disagreement Analysis Framework to Assess Group Associations in Perspectives
		</a><br>
                Vinodkumar Prabhakaran, Christopher M Homan, Lora Aroyo, <u>Aida Davani</u>,
		    Alicia Parrish, Alex Taylor, Mark Diaz, Ding Wang, Gregory Serapio-García<br>
		NAACL, 2024.
            </li>
	    <li>
                <a class="title" href="https://aclanthology.org/2023.findings-acl.425.pdf">
                    Distinguishing address vs. reference mentions of personal names in text</a><br>
                Vinodkumar Prabhakaran, <u>Aida Davani</u>, Melissa Ferguson, Stav Atir<br>
		ACL findings, 2023.
            </li>
	    <li>
                <a class="title" href="https://academic.oup.com/pnasnexus/article/2/7/pgad210/7220655">
                    The (moral) language of hate</a><br>
                Brendan Kennedy, Preni Golazizian, Jackson Trager, Mohammad Atari, Joe Hoover, <u>Aida Davani</u>, Morteza Dehghani<br>
		PNAS Nexus, 2023.
            </li>
	    <li>
                <a class="title" href="https://aclanthology.org/2023.acl-long.548.pdf">
                    SeeGULL: A stereotype benchmark with broad geo-cultural coverage leveraging generative models</a><br>
                Akshita Jha, <u>Aida Davani</u>, Chandan K Reddy, Shachi Dave, Vinodkumar Prabhakaran, Sunipa Dev<br>
		ACL, 2023.
            </li>
	    <li>
                <a class="title" href="https://www.nature.com/articles/s41598-023-32711-4">
                    The paucity of morality in everyday talk</a><br>
                Mohammad Atari, Matthias R. Mehl, Jesse Graham, John M. Doris, Norbert Schwarz, <u>Aida Davani</u>, Ali Omrani, Brendan Kennedy, ..., Morteza Dehghani <br>
                Scientific Reports, 2023.
            </li>
            <li>
                <a class="title" href="">
                    Hate speech classifiers learn normative social stereotypes</a><br>
                <u>Aida  Davani</u>, Mohammad Atari, Brendan Kennedy, Morteza Dehghani<br>
                TACL, 2022.
            </li>
            <li>
                <a class="title" href="">
                    Pathogens are linked to human moral systems across time and space</a><br>
                Mohammad Atari, Joseph Hoover, Brendan Kennedy, <u>Aida Davani</u>, Ali Omrani,
                Farzan Karimi-Malekabadi, Gwenyth Portillo-Wightman, Shirin Birjandi, Morteza Dehghani<br>
                 Current Research in Ecological and Social Psychology, 2022.
            </li>
            <li>
                <a class="title" href="https://arxiv.org/pdf/2110.05719.pdf">
                    Dealing with disagreements: Looking beyond the majority vote in subjective annotations
                </a><br>
                 <u>Aida Davani</u>, Mark Díaz, Vinodkumar Prabhakaran <br>
                TACL, 2021.
            </li>
            <li>
                <a class="title" href="https://arxiv.org/pdf/2110.05699.pdf">
                    On releasing annotator-level labels and information in datasets</a><br>
                Vinodkumar Prabhakaran*, <u>Aida Davani*</u>, Mark Díaz <br>
                LAW-DMR Workshop @ EMNLP, 2021.
            </li>
            <li>
                <a class="title" href="https://arxiv.org/pdf/2108.01721.pdf">
                    Improving counterfactual generation for fair hate speech detection</a><br>
                 <u>Aida Davani</u>, Ali Omrani, Mohammad Atari, Brendan Kennedy,
                 Xiang Ren, Morteza Dehghani <br>
                WOAH Workshop @ ACL, 2021.
            </li>


            <li>
                <a class="title" href="https://psyarxiv.com/h3udp/">Morally homogeneous networks and radicalism</a><br>
                    Mohammad Atari, <u>Aida Davani</u>, Drew Kogon,
                        Brendan Kennedy, Nripsuta Ani Saxena, Ian Anderson, Morteza Dehghani<br>
                    Social Psychological and Personality Science, 2021.
            </li>
             <li>
                    <a class="title" href="https://psyarxiv.com/hqjxn/">
                        The gab hate corpus: A collection of 27k posts annotated for hate speech</a><br>
                    Brendan Kennedy, Mohammad Atari, <u>Aida Davani</u>, Leigh Yeh, Ali Omrani,
                    Joseph Hoover, ..., Morteza Dehghani<br>
                    Language Resources and Evaluation, 2021.
            </li>
            <li>
                <a class="title" href="https://www.nature.com/articles/s41467-021-24786-2">
                    Investigating the role of group-based morality in extreme behavioral
                    expressions of prejudice</a><br>
                 Joseph Hoover, Mohammad Atari*, <u>Aida Davani</u>*, Brendan Kennedy*,
                Gwenyth Portillo-Wightman, Leigh Yeh, Morteza Dehghani <br>
                Nature Communications, 2021.
            </li>

            <li>
                <a class="title" href="https://psyarxiv.com/uqmty/">
                    Moral concerns are differentially observable in language</a><br>
                 Brendan Kennedy, Mohammad Atari, <u>Aida Davani</u>, Joseph Hoover, Ali Omrani, Jesse
                 Graham, Morteza Dehghani<br>
                Cognition, 2021.
            </li>
            <li>
            <a class="title" href="https://arxiv.org/pdf/2010.12864.pdf">
                On transferability of bias mitigation effects in language model fine-tuning</a><br>
                Xisen Jin, Francesco Barbieri, Brendan Kennedy, <u>Aida Davani</u>, Leonardo Neves, Xiang Ren<br>
                NAACL, 2021.
            </li>
            <li>
                <a class="title" href="">
                Hatred is in the eye of the annotator: Hate speech classifiers learn human-like social stereotypes</a><br>
                <u>Aida Davani</u>, Mohammad Atari, Brendan Kennedy, Shreya Havaldar, Morteza Dehghani<br>
                CogSci, 2020.
            </li>
            <li>
                <a class="title" href="https://arxiv.org/pdf/2005.02439.pdf">
                    Contextualizing hate speech classifiers with post-hoc explanation</a><br>
                Brendan Kennedy*, Xisen Jin*, <u>Aida Davani</u>, Morteza Dehghani, Xiang Ren <br>
                ACL, 2020.
            </li>
            <li>
                <a class="title" href="https://journals.sagepub.com/doi/abs/10.1177/1948550619876629">
                    Moral Foundations Twitter Corpus: A collection of 35k tweets annotated for moral sentiment</a><br>
                Joe Hoover, Gwenyth Portillo-Wightman, Leigh Yeh, Shreya Havaldar, <u>Aida Davani</u>
                , Ying Lin, Brendan Kennedy, Mohammad Atari, Zahra Kamel, Madelyn Mendlen, Gabriela Moreno,
                Christina Park, Tingyee E Chang, Jenna Chin, Christian Leong,
                Jun Yen Leung, Arineh Mirinjian, Morteza Dehghani.
                <br>
                Social Psychological and Personality Science, 2020.
            </li>

            <li>
                <a class="title" href="https://arxiv.org/pdf/1909.02126.pdf">Reporting the unreported:
                    Event extraction for analyzing the local representation of hate crimes</a><br>
                <u>Aida Davani</u>, Leigh Yeh, Mohammad Atari, Brendan Kennedy, Gwenyth Portillo-Wightman,
                , Natalie Delong, Rhea Bhatia, Arineh Mirinjian, Xiang Ren, Morteza Dehghani <br>
                EMNLP, 2019.
            </li>

            <li>
                <a class="title" href="https://www.aclweb.org/anthology/W19-2106.pdf">Modeling performance
                    differences on cognitive tests using LSTMs and
                skip-thought vectors trained on reported media consumption</a><br>
                Maury Courtland, <u>Aida Davani</u>, Melissa Reyes, Leigh Yeh, Jun Leung, Brendan Kennedy,
                Morteza Dehghani, Jason Zevin <br>
                NLP+CSS Workshop @ NAACL, 2019.

            </li>

            <li>
                <a class="title" href="https://tinyurl.com/y9wuwou3">
                    Subtle differences in language experience moderate
                performance on language-based cognitive tests.</a><br>
                Maury Courtland, <u>Aida Davani</u>, Melissa Reyes, Leigh Yeh, Jun Leung, Brendan Kennedy,
                Morteza Dehghani, Jason Zevin<br>
                CogSci, 2019.
            </li>

            <li>
                <a class="title" href="https://psyarxiv.com/jkewf">Body maps of moral concerns</a><br>
                Mohammad Atari, <u>Aida Davani</u>, Morteza Dehghani<br>
                Psychological Science, 2019.
            </li>

        </ul>
        </div>
        <div class="right_div">
            <h2 class="right">Pre-prints and In-progress</h2>
            <ul>

                <li>
                    <a class="title" href="">
                        Syntactic and semantic gender biases in the language on children’s television: Evidence from
                        a corpus of 95 shows from 1960 to 2018</a><br>
                    Andrea C. Vial*, <u>Aida Davani*</u>,
                    Shreya Havaldar, Eleanor K. Chestnut, Morteza Dehghani, Andrei Cimpian<br>
                </li>
                <li>
                    <a class="title" href="https://arxiv.org/pdf/2404.10857">
                        D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation</a><br>
                    <u>Aida Davani</u>, Mark Díaz, Dylan Baker, Vinodkumar Prabhakaran<br>
                </li>
            </ul>
        </div>


    </div>
</div>
</body>

